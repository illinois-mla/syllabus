{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and Statistics for Physicists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the function below to calculate the event probabilities $P(A)$, $P(B)$, $P(A \\cap B)$ and the conditional probabilities $P(A\\mid B)$, $P(B\\mid A)$ for an arbitrary (finite) probability space specified by each outcome's probability. *Hint: the probability of an event containing a set of outcomes is just the sum of the individual outcome probabilities.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b26b6b06ed8a18e4adf32c56dbe69184",
     "grade": false,
     "grade_id": "cell-645c193e9e70befb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_probabilities(p, A, B):\n",
    "    \"\"\"Calculate probabilities for an arbitrary probability space.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p : float array of shape (N,)\n",
    "        Probabilities for each of the N possible outcomes in the probability space.\n",
    "    A : boolean array of shape (N,)\n",
    "        Identifies members of event set A in the probability space.\n",
    "    B : boolean array of shape (N,)\n",
    "        Identifies members of event set B in the probability space.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Tuple of five probabilities values:\n",
    "        P(A), P(B), P(A instersect B), P(A | B), P(B | A).\n",
    "    \"\"\"\n",
    "    assert np.all((p >= 0) & (p <= 1))\n",
    "    assert np.sum(p) == 1\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0f009ae6e95034f20e3084493c61390f",
     "grade": true,
     "grade_id": "cell-b092ca5941d722a0",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# A correction solution should pass the tests below.\n",
    "gen = np.random.RandomState(seed=123)\n",
    "N = 100\n",
    "p = gen.uniform(size=(4, N))\n",
    "p = (p / p.sum(axis=1).reshape(-1, 1)).reshape(-1) / 4.\n",
    "\n",
    "# Test when A and B are \"independent\" events, i.e., P(A interset B) = P(A) P(B).\n",
    "A = np.arange(4 * N) < 2 * N\n",
    "B = (np.arange(4 * N) >= N) & (np.arange(4 * N) < 3 * N)\n",
    "assert np.allclose(\n",
    "    np.round(calculate_probabilities(p, A, B), 3),\n",
    "    [0.5, 0.5, 0.25, 0.5, 0.5])\n",
    "\n",
    "# Test with randomly generated events A, B.\n",
    "A = gen.uniform(size=4*N) < 0.3\n",
    "B = gen.uniform(size=4*N) > 0.6\n",
    "#print(np.round(event_probabilities(p, A, B), 3))\n",
    "assert np.allclose(\n",
    "    np.round(calculate_probabilities(p, A, B), 3),\n",
    "    [0.278, 0.33, 0.076, 0.23, 0.273])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative distribution function (CDF) is the fundamental representation of a random variable, rather than the probability density function (PDF) which might not be defined, is not a probability and generally has dimensions. In this problem, you will explore a practical application of the CDF for generating random numbers.\n",
    "\n",
    "Since the CDF $y = F_X(x)$ maps from random variable values to the range $[0,1]$, its inverse $x = F_X^{-1}(y)$ maps from $[0,1]$ back to the random variable. What distribution of $y$ values would generate values according to the PDF $f_X(x)$ when transformed by the inverse $F_X^{-1}(y)$? The answer is a uniform distribution, as we can demonstrate numerically for an arbitrary random variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf_hist(X, n=10000, seed=123):\n",
    "    gen = np.random.RandomState(seed=seed)\n",
    "    # Generate n random value from the scipy.stats distribution X.\n",
    "    x = X.rvs(n, random_state=gen)\n",
    "    plt.hist(x, bins=50, label='$f_X(x)$', histtype='step', lw=2, normed=True)\n",
    "    # Histogram the corresponding CDF values.\n",
    "    y = X.cdf(x)\n",
    "    plt.hist(y, bins=20, label='$F_X(x)$', alpha=0.5, normed=True)\n",
    "    plt.xlabel('x')\n",
    "    plt.legend(loc='upper center', ncol=2)\n",
    "    \n",
    "cdf_hist(scipy.stats.beta(0.9, 1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the function $F_X(x)$ can be inverted analytically, you can use it to transform uniformly generated random values into a random sampling of the PDF $f_X(x)$.\n",
    "\n",
    "For example, consider random outcomes consisting of $(x,y)$ points uniformly distributed on the disk,\n",
    "$$\n",
    "0 \\le r_1 \\le \\sqrt{x^2 + y^2} \\le r_2 \\; .\n",
    "$$\n",
    "The CDF of the random variable $r \\equiv \\sqrt{x^2 + y^2}$ is then\n",
    "$$\n",
    "F_R(r) = \\begin{cases}\n",
    "1 & r > r_2 \\\\\n",
    "\\frac{r^2 - r_1^2}{r_2^2 - r_1^2} & r_1 \\le r \\le r_2 \\\\\n",
    "0 & r < r_1\n",
    "\\end{cases}\\; .\n",
    "$$\n",
    "Implement the function below to apply $F_R^{-1}(y)$ to uniformly distributed random values in order to sample $f_R(x)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2a2e46bb7d660eee48c482275e01871b",
     "grade": false,
     "grade_id": "cell-4a3969cc21bad440",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def sample_disk(r1, r2, n, gen):\n",
    "    \"\"\"Sample random radii for points uniformly distributed on a disk.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    r1 : float\n",
    "        Inner radius of disk.\n",
    "    r2 : float\n",
    "        Outer radius of disk.\n",
    "    n : int\n",
    "        Number of random samples to generate.\n",
    "    gen : np.random.RandomState\n",
    "        Random state for reproducible random numbers.\n",
    "        Uses gen.uniform() internally, not gen.rand().\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        Array of n randomly generated r values.\n",
    "    \"\"\"\n",
    "    assert (r1 >= 0) and (r1 < r2)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "482cb262e3fbc52364028d4c45041b77",
     "grade": true,
     "grade_id": "cell-8bd5af1a46e05050",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# A correct solution should pass these tests.\n",
    "r1, r2, n = 1., 2., 1000\n",
    "gen = np.random.RandomState(seed=123)\n",
    "r = sample_disk(r1, r2, n, gen)\n",
    "assert np.all((r >= r1) & (r <= r2))\n",
    "assert np.allclose(np.round(np.mean(r), 3), 1.556)\n",
    "assert np.allclose(np.round(np.std(r), 3), 0.279)\n",
    "\n",
    "r1, r2, n = 0., 2., 1000\n",
    "r = sample_disk(r1, r2, n, gen)\n",
    "assert np.all((r >= r1) & (r <= r2))\n",
    "assert np.allclose(np.round(np.mean(r), 3), 1.325)\n",
    "assert np.allclose(np.round(np.std(r), 3), 0.494)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your implementation by plotting some $(x,y)$ points with uniformly random $0 \\le \\theta < 2\\pi$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = np.random.RandomState(seed=123)\n",
    "r = sample_disk(0.8, 1.2, 1000, gen)\n",
    "theta = gen.uniform(0, 2 * np.pi, size=len(r))\n",
    "plt.scatter(r * np.cos(theta), r * np.sin(theta), s=5)\n",
    "plt.gca().set_aspect(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes $F_X(x)$ cannot be inverted explicitly, either because the inverse has no closed form or because the underlying distribution is arbitrary.  In these cases, we can still apply the same method numerically.\n",
    "\n",
    "Implement the function below to tabulate an empirical estimate of the CDF for an arbitrary random variable, as:\n",
    "$$\n",
    "x_{CDF} = x_{\\text{lo}}, x_0, x_1, \\ldots, x_{N-1}, x_{\\text{hi}} \\; ,\n",
    "$$\n",
    "where the $x_i$ are [sorted](https://docs.scipy.org/doc/numpy/reference/generated/numpy.interp.html), $x_0 \\le x_1 \\le \\ldots \\le x_{N-1}$, and corresponding CDF values:\n",
    "$$\n",
    "y_{CDF} = 0, \\frac{1}{N+1}, \\frac{2}{N+1}, \\ldots, \\frac{N}{N+1}, 1 \\; .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "138a812d73f24fb2fd6c8f076d521734",
     "grade": false,
     "grade_id": "cell-dfbdb3a404b995da",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def empirical_cdf(x, xlo, xhi):\n",
    "    \"\"\"Tabulate the empirical CDF from samples of an arbitrary random variable.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array of shape (N,)\n",
    "        Array of input random variable values to use.\n",
    "    xlo : float\n",
    "        Low limit for the random variable x.\n",
    "    xhi : float\n",
    "        High limit for the random variable x.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Tuple (x_cdf, y_cdf) of arrays both of shape (N+2,), padded at each end\n",
    "        as described above.\n",
    "    \"\"\"\n",
    "    assert xlo < xhi\n",
    "    x = np.asarray(x)\n",
    "    assert np.all((x >= xlo) & (x <= xhi))\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0617fe018478f97682df7cca6a2dd811",
     "grade": true,
     "grade_id": "cell-f256ef9551b29f56",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# A correct solution should pass these tests.\n",
    "x_cdf, y_cdf = empirical_cdf([1, 2, 3, 4], 0, 5)\n",
    "assert np.array_equal(x_cdf, [0, 1, 2, 3, 4, 5])\n",
    "assert np.allclose(y_cdf, [0., .2, .4, .6, .8, 1.])\n",
    "\n",
    "x_cdf, y_cdf = empirical_cdf([4, 2, 1, 3], 0, 5)\n",
    "assert np.array_equal(x_cdf, [0, 1, 2, 3, 4, 5])\n",
    "assert np.allclose(y_cdf, [0., .2, .4, .6, .8, 1.])\n",
    "\n",
    "gen = np.random.RandomState(seed=123)\n",
    "x = scipy.stats.beta(0.9, 1.5).rvs(size=4, random_state=gen)\n",
    "x_cdf, y_cdf = empirical_cdf(x, 0., 1.)\n",
    "assert np.allclose(\n",
    "    np.round(x_cdf, 3),\n",
    "    [ 0.   ,  0.087,  0.152,  0.42 ,  0.721,  1.   ])\n",
    "assert np.allclose(y_cdf, [0., .2, .4, .6, .8, 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your implementation by generating CDF samples matched to an unknown distribution.  Note that we use [linear interpolation](https://docs.scipy.org/doc/numpy/reference/generated/numpy.interp.html) to numerically invert the empirical CDF in this approach, which is a useful trick to remember:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "gen = np.random.RandomState(seed=123)\n",
    "X = scipy.stats.beta(0.9, 1.5)\n",
    "# Generate samples using scipy.stats\n",
    "x_in = X.rvs(n, random_state=gen)\n",
    "plt.hist(x_in, bins=50, label='Input data', alpha=0.5, normed=True)\n",
    "# Generate samples using the empirical CDF of x_in\n",
    "x_cdf, y_cdf = empirical_cdf(x_in, 0., 1.)\n",
    "y = gen.uniform(size=n)\n",
    "x = np.interp(y, y_cdf, x_cdf)\n",
    "plt.hist(x, bins=50, label='CDF samples', histtype='step', lw=2, normed=True)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We showed that the conditional probability density of a multidimensional feature space can be calculated as:\n",
    "$$\n",
    "f_{X|Y}(\\vec{x}\\mid \\vec{y}) = \\frac{f(\\vec{x}, \\vec{y})}{f(\\vec{y})} \\; ,\n",
    "$$\n",
    "where features $\\vec{x}$ are conditioned on the values of features $\\vec{y}$.\n",
    "\n",
    "For the ubiquitous multivariate normal probability density, we can split the joint mean $\\vec{\\mu}_{X,Y}$ into separate means for the $X$ and $Y$ features,\n",
    "$$\n",
    "\\vec{\\mu}_{X,Y} = \\begin{bmatrix}\\vec{\\mu}_X \\\\ \\vec{\\mu}_Y\\end{bmatrix}\n",
    "$$\n",
    "and, similarly, for the joint covariance:\n",
    "$$\n",
    "C_{X,Y} = \\begin{bmatrix}\n",
    "C_{XX} & C_{XY} \\\\\n",
    "C_{XY} & C_{YY}\n",
    "\\end{bmatrix} \\; ,\n",
    "$$\n",
    "where $C_{XX}$ is the submatrix of covariances for the $X$ features, etc.\n",
    "\n",
    "We can then explicitly calculate the resulting marginal mean:\n",
    "$$\n",
    "\\vec{\\mu}_{X|Y} \\equiv \\langle \\vec{x}\\rangle_{X|Y} = \\vec{\\mu}_X + C_{XY} C_{YY}^{-1} \\left(\\vec{y} - \\vec{\\mu}_Y\\right) \\; ,\n",
    "$$\n",
    "and covariance\n",
    "$$\n",
    "C_{X|Y} \\equiv \\langle \\left( \\vec{x} - \\vec{\\mu}_{X|Y}\\right)\n",
    "\\left( \\vec{x} - \\vec{\\mu}_{X|Y}\\right)^T \\rangle_{X|Y} = C_{XX} - C_{XY} C_{YY}^{-1} C_{XY}^T \\; .\n",
    "$$\n",
    "\n",
    "Note that $\\vec{\\mu}_{X|Y}$ depends on the conditioned feature values $\\vec{y}$, but $C_{X|Y}$ does not. These Gaussian conditional probability densities are central to the Factor Analysis (FA) and Gaussian Process (GP) methods.\n",
    "\n",
    "Implement the function below to calculate these expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "33f1c6dcef858112f88fb75046332cf0",
     "grade": false,
     "grade_id": "cell-f59d554e2859fb8d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gauss_conditional_predicted(y0, muX, muY, CXX, CXY, CYY):\n",
    "    \"\"\"Predicted conditional Gaussian means and covariances.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y0 : array of shape (ny,)\n",
    "        Fixed y values used for conditioning.\n",
    "    muX : array of shape (nx,)\n",
    "        Mean value of X features.\n",
    "    muY : array of shape (ny,)\n",
    "        Mean value of Y features.\n",
    "    CXX : array of shape (nx, nx)\n",
    "        Covariances between X features.\n",
    "    CXY : array of shape (nx, ny)\n",
    "        Covariances between X and Y features.\n",
    "    CYY : array of shape (ny, ny)\n",
    "        Covariances between Y features.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Tuple (mu, C) of arrays with shapes (nx,) and (nx,nx), respectively,\n",
    "        giving the means and covariances of X features conditioned on Y=y0.\n",
    "    \"\"\"\n",
    "    nx = len(muX)\n",
    "    ny = len(muY)\n",
    "    assert y0.shape == (ny,)\n",
    "    assert CXX.shape == (nx, nx)\n",
    "    assert CXY.shape == (nx, ny)\n",
    "    assert CYY.shape == (ny, ny)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ec0add892f6887326b767361e387eb4a",
     "grade": true,
     "grade_id": "cell-b183a421b6e7a481",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# A correct solution should pass these tests.\n",
    "nx, ny = 2, 3\n",
    "y0, muX, muY = np.ones(ny), np.zeros(nx), np.zeros(ny)\n",
    "CXX, CXY, CYY = np.identity(nx), np.zeros((nx, ny)), np.identity(ny)\n",
    "mu, C = gauss_conditional_predicted(y0, muX, muY, CXX, CXY, CYY)\n",
    "assert np.allclose(mu, [0, 0])\n",
    "assert np.allclose(C, [[1, 0], [0, 1]])\n",
    "\n",
    "y0, muX, muY = np.array([1, 2]), np.array([3, 2, 1]), np.array([0, 0])\n",
    "CXX, CXY, CYY = np.array([[2, 0, 1], [0, 1, 0], [1, 0, 1]]), np.zeros((3, 2)), np.array([[1, 1], [1, 2]])\n",
    "mu, C = gauss_conditional_predicted(y0, muX, muY, CXX, CXY, CYY)\n",
    "assert np.allclose(mu, [3, 2, 1])\n",
    "assert np.allclose(C, [[ 2, 0, 1],  [0, 1, 0], [1, 0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the function below to calculate empirical estimates of the conditional Gaussian means and covariances. Since the requirement $Y = y_0$ will likely not select *any* samples from a finite dataset, we relax this condition to:\n",
    "$$\n",
    "\\left| \\vec{y} - \\vec{y}_0\\right|^2 < \\epsilon^2 \\; ,\n",
    "$$\n",
    "and apply `np.mean` and `np.cov` to the resulting subset of samples. *Hint: pay attention to the `rowvar` parameter of `np.cov`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "40b873c6a51e62f8076bc0b263e1265d",
     "grade": false,
     "grade_id": "cell-828d01589aacbead",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gauss_conditional_measured(X, Y, y0, eps=1.5):\n",
    "    \"\"\"Measured conditional Gaussian means and covariances.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array of shape (N, nx)\n",
    "        X feature values for dataset with N samples.\n",
    "    Y : array of shape (N, ny)\n",
    "        Y feature values for dataset with N samples.\n",
    "    y0 : array of shape (ny,)\n",
    "        Fixed y values used for conditioning.\n",
    "    eps : float\n",
    "        Tolerance for selecting samples with Y ~ y0.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Tuple (mu, C) of arrays with shapes (nx,) and (nx,nx), respectively,\n",
    "        giving the means and covariances of X features conditioned on Y=y0.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "114b40c999caca32ed5372bb88686d2d",
     "grade": true,
     "grade_id": "cell-d14a84cc58280262",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# A correct solution should pass these tests.\n",
    "# Repeat the first test above, but numerically this time.\n",
    "gen = np.random.RandomState(seed=123)\n",
    "nx, ny = 2, 3\n",
    "y, muX, muY = np.ones(ny), np.zeros(nx), np.zeros(ny)\n",
    "CXX, CXY, CYY = np.identity(nx), np.zeros((nx, ny)), np.identity(ny)\n",
    "mu = np.hstack([muX, muY])\n",
    "C = np.block([[CXX, CXY], [CXY.T, CYY]])\n",
    "XY = gen.multivariate_normal(mu, C, size=1000000)\n",
    "mu, C = gauss_conditional_measured(XY[:, :nx], XY[:, nx:], y)\n",
    "assert np.allclose(np.round(mu, 2), [0, 0])\n",
    "assert np.allclose(np.round(C, 2), [[1, 0], [0, 1]])\n",
    "\n",
    "# Repeat the second test above, but numerically this time.\n",
    "y, muX, muY = np.array([1, 2]), np.array([3, 2, 1]), np.array([0, 0])\n",
    "CXX, CXY, CYY = np.array([[2, 0, 1], [0, 1, 0], [1, 0, 1]]), np.zeros((3, 2)), np.array([[1, 1], [1, 2]])\n",
    "mu = np.hstack([muX, muY])\n",
    "C = np.block([[CXX, CXY], [CXY.T, CYY]])\n",
    "XY = gen.multivariate_normal(mu, C, size=1000000)\n",
    "mu, C = gauss_conditional_measured(XY[:, :3], XY[:, 3:], y)\n",
    "assert np.allclose(np.round(mu, 2), [3, 2, 1])\n",
    "assert np.allclose(np.round(C, 2), [[ 2, 0, 1],  [0, 1, 0], [1, 0, 1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
